# ðŸ§¹ Titanic Dataset â€“ Data Cleaning & Exploratory Data Analysis (EDA)

## ðŸ“ Project Overview

This project involves **data cleaning** and **exploratory data analysis (EDA)** on the Titanic dataset to identify patterns, clean the data, and prepare it for predictive modeling.

Key objectives:
- Clean and preprocess real-world data
- Identify missing and inconsistent values
- Explore relationships between variables such as `Survived`, `Pclass`, `Sex`, and `Age`
- Visualize insights with charts and statistical plots

---

## ðŸ—‚ï¸ Dataset Description

The dataset used is the [Titanic dataset](https://www.kaggle.com/c/titanic/data), which contains details of passengers aboard the Titanic.

Files included:
- `train.csv` â€“ Training dataset with survival outcomes
- `test.csv` â€“ Test dataset without survival outcomes
- `gender_submission.csv` â€“ Sample submission for Kaggle
- `.png` files â€“ Visualizations created using EDA

---

## ðŸ“Š Visualizations

ðŸ“· Sample plots generated during EDA:
- `age_distribution_by_survival.png`
- `distribution_of_survival.png`
- `pairplot_survived.png`
- `survival_by_gender.png`
- `survival_by_pclass.png`

These help in visualizing:
- Survival rate distribution
- Class and gender impact on survival
- Age distribution among survivors and non-survivors

---

## ðŸ§° Technologies Used

- ðŸ Python
- ðŸ“š Pandas
- ðŸ“Š Matplotlib
- ðŸŒˆ Seaborn
- ðŸ’» Visual Studio Code (VS Code)

---

## âš™ï¸ Features Implemented

- âœ… Handled missing values (Age, Cabin, Embarked)
- âœ… Converted categorical data for better visualization
- âœ… Removed duplicates
- âœ… Created statistical plots using Seaborn and Matplotlib
- âœ… Cleaned dataset ready for model training

---

## ðŸ“Œ How to Run

1. Clone the repository  
2. Open in VS Code  
3. Run `titanic.py` or open Jupyter Notebook if preferred  
4. Ensure required libraries (`pandas`, `matplotlib`, `seaborn`) are installed

```bash
pip install pandas matplotlib seaborn

> ðŸ“Œ **Task 02 â€“ Data Cleaning & EDA**  
> âœ… Completed as part of the **Data Science Internship** at **Prodigy InfoTech**

---
